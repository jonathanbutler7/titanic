{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d134201f",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "project introduction:\n",
    "\n",
    "this jupyter notebook implements a machine learning workflow to predict\n",
    "whether passengers survived the Titanic disaster using a Logistic\n",
    "Regression model. The exercise uses the Titanic dataset from kaggle, \n",
    "which includes passenger information such as class, sex, age, and\n",
    "fare, to train and evaluate a classifier.  \n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdfbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0617b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv files and convert them into pandas data frames that we can work with\n",
    "# to train a classifier that uses passenger data to make predictions about whether \n",
    "# or not each passenger survived. we will compare the predictions against a source\n",
    "# of truth to determine the accuracy of the model and potentially make some improvements\n",
    "\n",
    "# train.csv contains passenger features and survival outcomes (Survived), used to train\n",
    "# the model. test.csv contains features only, used to predict survival for submission.\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# test_ids is used at the very end of the exercise once we have a prediction\n",
    "# for each row. we'll use the passenger ids to indicate the results of the model\n",
    "test_passenger_ids = test[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af76088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FamilyCat</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>Title</th>\n",
       "      <th>HasCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex Embarked AgeBin FamilyCat FareBin Title  HasCabin\n",
       "0         0       3    male        S      2         1       0    Mr         0\n",
       "1         1       1  female        C      3         1       3   Mrs         1\n",
       "2         1       3  female        S      2         0       1  Miss         0\n",
       "3         1       1  female        S      2         1       3   Mrs         1\n",
       "4         0       3    male        S      2         0       1    Mr         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the data and limit to the \"features\" (column names) we want to use\n",
    "# in the Logistic Regression classifier below.\n",
    "def clean(data):\n",
    "    \n",
    "    # drop the following columns, as they will not be used in classifying\n",
    "    # whether a passenger lived or died. cabin would actually be a good\n",
    "    # thing to consider, if we could know where the cabin was located on\n",
    "    # the ship. for example, do cabins closer to lifeboats, or further away\n",
    "    # from point of impact (etc) correlate with survival rates?\n",
    "    data = data.drop([\"Ticket\", \"PassengerId\"], axis=1)\n",
    "    \n",
    "    # these numerical columns have some missing values. let's list them\n",
    "    # and clean them up in the `for` loop below\n",
    "    # cols = [ \"Parch\"]\n",
    "\n",
    "    # if the cell value is empty, fill it with that column's median\n",
    "    # value. i have mixed feelings about replacing na values with \n",
    "    # median. i guess it wouldn't throw off or skew the Logistic \n",
    "    # Regression classifier significantly, but it seems like it \n",
    "    # would reduce the variability of the data. is it enough \n",
    "    # to be a problem?\n",
    "    # for col in cols:\n",
    "    #     data.fillna({col: data[col].median()}, inplace=True)\n",
    "    \n",
    "    data['AgeBin'] = pd.cut(data['Age'], bins=[0, 12, 18, 35, 60, 120], labels=[0, 1, 2, 3, 4])\n",
    "    \n",
    "    # an alternative to filling the age column's empty rows with \n",
    "    # the median is to add a new category and fill na rows with it\n",
    "    data['AgeBin'] = data['AgeBin'].cat.add_categories(['Missing']).fillna('Missing')\n",
    "    data = data.drop(['Age'], axis=1)\n",
    "    \n",
    "    # fill na with S because that is the most commonly embarked location. \n",
    "    # adding an Unknown value here would just increase the number \n",
    "    # of possible categories this is handled  # outside of the for \n",
    "    # loop because Embarked is categorical, unlike the numerical columns above\n",
    "    data['Embarked'] = data[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    # create a new column in the data that accounts for the size of \n",
    "    # the passengers family. add one at the end to include the \n",
    "    # passenger\n",
    "    data[\"FamilyCount\"] = data[\"SibSp\"] + data[\"Parch\"] + 1\n",
    "    data['FamilyCat'] = pd.cut(\n",
    "        data['FamilyCount'], \n",
    "        bins=[0, 1, 4, 11], \n",
    "        # alone, small large. use numbers here instead of words\n",
    "        labels=[0, 1, 2]\n",
    "    )\n",
    "    data = data.drop(['SibSp', 'Parch', 'FamilyCount'], axis=1)\n",
    "    \n",
    "    # fare has a very wide range of 0-500+, which can skew the \n",
    "    # Logistic Regression model, as it assumes linear relationships.\n",
    "    # binning into equally sized groups reduces sensitivity to outliers\n",
    "    # and captures which fare ranges may correlate with survival\n",
    "    data['FareBin'] = pd.qcut(data['Fare'], 4, labels=[0, 1, 2, 3])\n",
    "    data = data.drop(['Fare'], axis=1)\n",
    "    \n",
    "    # extract any substring of the Name column that ends with `.`\n",
    "    # this is useful because, to an extent, we can infer social \n",
    "    # status and age from the title.\n",
    "    data['Title'] = data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # handle some of the edge cases\n",
    "    data['Title'] = data['Title'].replace(\n",
    "        ['Lady', 'Countess', 'Capt', 'Col', 'Don', \n",
    "         'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], \n",
    "        # replace uncommon values with a single value, so \n",
    "        # as to allow the model to focus on more common values\n",
    "        'Rare'\n",
    "    )\n",
    "    data['Title'] = data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    data['HasCabin'] = data['Cabin'].notnull().astype(int)\n",
    "    \n",
    "    data = data.drop(\"Cabin\", axis=1)\n",
    "    data = data.drop('Name', axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# use and reuse the clean function to clean the data for both sets\n",
    "data = clean(data)\n",
    "test = clean(test)\n",
    "\n",
    "# preview the cleaned data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67795613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n",
      "['C' 'Q' 'S']\n",
      "['Master' 'Miss' 'Mr' 'Mrs' 'Rare']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FamilyCat</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>Title</th>\n",
       "      <th>HasCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Embarked   AgeBin FamilyCat FareBin  Title  HasCabin\n",
       "0         0       3    1         2        2         1       0      2         0\n",
       "1         1       1    0         0        3         1       3      3         1\n",
       "2         1       3    0         2        2         0       1      1         0\n",
       "3         1       1    0         2        2         1       3      3         1\n",
       "4         0       3    1         2        2         0       1      2         0\n",
       "5         0       3    1         1  Missing         0       1      2         0\n",
       "6         0       1    1         2        3         0       3      2         1\n",
       "7         0       3    1         2        0         2       2      0         0\n",
       "8         1       3    0         2        2         1       1      3         0\n",
       "9         1       2    0         0        1         1       2      3         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# instantiate a LabelEncoder to use on Sex and Embarked.\n",
    "# this will assign 0 to female and a 1 to male. need \n",
    "# to do this  because LogisticRegression requires all \n",
    "# numeric inputs\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "cols = [\"Sex\", \"Embarked\", \"Title\"]\n",
    "\n",
    "# for col in cols:\n",
    "#     le.fit(data[col])\n",
    "#     data[col] = le.transform(data[col])\n",
    "#     test[col] = le.transform(test[col])\n",
    "# encode Sex (e.g., female=0, male=1) and Embarked (e.g., C=0, Q=1, S=2, U=3).\n",
    "for col in cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "    # le.classes_ shows the unique values that the encoder has \n",
    "    # identified and will transform into more readable values\n",
    "    # that will be used in the modeling\n",
    "    print(le.classes_)\n",
    "\n",
    "# check out the first 10 rows of the transformed data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f74f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract Survived as the target (y) and other columns as features (X)\n",
    "\n",
    "# make a copy of the survived column off of the data frame\n",
    "y = data[\"Survived\"]\n",
    "# after making the copy, drop the column before we pass it into the training\n",
    "X = data.drop(\"Survived\", axis=1)\n",
    "\n",
    "# divide the data into two parts: one to train the model (80%) and \n",
    "# another to test its predictions (20%). this split is important to \n",
    "# check how well the model works on new, unseen data, ensuring it \n",
    "# doesn’t just memorize the training data. can't use the complete dataset \n",
    "# for both training and testing would overestimate the model’s \n",
    "# performance, as it would already know the answers. test_size=0.2 \n",
    "# means 20% is used for testing, and random_state=42 keeps the split \n",
    "# consistent each time the code runs.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393c4a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Missing'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/6v/r791v73x5ld7ck2l7tk19xvr0000gn/T/ipykernel_30071/2879608236.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# survival. `.fit` uses the training data to figure out how much each trait\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# matters for predicting whether someone survived or died, preparing the\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# model to make predictions later. random_state=0 keeps results consistent,\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# and max_iter=1000 ensures the model finishes learning.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m clf = LogisticRegression(random_state=\u001b[32m0\u001b[39m, max_iter=\u001b[32m1000\u001b[39m).fit(X_train, y_train)\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# printing the feature coefficients shows that the strongest indicator of\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# survival was \"Sex\", which had a coefficient of 2.6.\u001b[39;00m\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1243\u001b[39m             _dtype = np.float64\n\u001b[32m   1244\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m             _dtype = [np.float64, np.float32]\n\u001b[32m   1246\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m         X, y = validate_data(\n\u001b[32m   1248\u001b[39m             self,\n\u001b[32m   1249\u001b[39m             X,\n\u001b[32m   1250\u001b[39m             y,\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Missing'"
     ]
    }
   ],
   "source": [
    "# this seems to be the real ML part of the model. LogisticRegression takes in\n",
    "# the training data, which includes the `Survived` column. this is important\n",
    "# because we need to start to draw conclusions from the characteristics of \n",
    "# those who survived and those who did not. the `clf` name is a convention that\n",
    "# is an abbreviation for \"classifier\"\n",
    "\n",
    "# train the model to learn which passenger traits (like sex or class) predict \n",
    "# survival. `.fit` uses the training data to figure out how much each trait\n",
    "# matters for predicting whether someone survived or died, preparing the \n",
    "# model to make predictions later. random_state=0 keeps results consistent, \n",
    "# and max_iter=1000 ensures the model finishes learning.\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "# printing the feature coefficients shows that the strongest indicator of\n",
    "# survival was \"Sex\", which had a coefficient of 2.6. \n",
    "print(\"Feature Coefficients:\", dict(zip(X.columns, clf.coef_[0])))\n",
    "\n",
    "# todo: look into what intercept is\n",
    "print(\"Intercept:\", clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef38830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/arrays/categorical.py:1692: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(ret, dtype=dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict survival on the validation set. clf.predict computes probabilities and\n",
    "# outputs 1 (survived) if >= 0.5, or 0 (died)\n",
    "predictions = clf.predict(X_val)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# calculate accuracy by comparing predictions to true labels (y_val). 81% accuracy\n",
    "# means 81% of predictions are correct\n",
    "accuracy_score(y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f2660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/arrays/categorical.py:1692: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(ret, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "# predict survival for the test set. clf.predict outputs 1 (survived) if probability\n",
    "# >= 0.5, else 0 (died), for submission\n",
    "submission_preds = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame with PassengerId and Survived columns.\n",
    "# test_passenger_ids.values is a list of passenger ids that was\n",
    "# declared in the first codeblock at the top of this notebook.\n",
    "# submission_preds is a list of 0s and 1s indicating the results of\n",
    "# the predictive model. 0 is \"died\" and 1 is \"survived\"\n",
    "df = pd.DataFrame({ \"PassengerId\": test_passenger_ids.values, \"Survived\": submission_preds })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171929d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data frame into a csv. \n",
    "# index=False excludes index values from being added\n",
    "# to each row\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
