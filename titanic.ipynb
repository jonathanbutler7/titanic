{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d134201f",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "project introduction:\n",
    "\n",
    "this jupyter notebook implements a machine learning workflow to predict\n",
    "whether passengers survived the Titanic disaster using a Logistic\n",
    "Regression model. The exercise uses the Titanic dataset from kaggle, \n",
    "which includes passenger information such as class, sex, age, and\n",
    "fare, to train and evaluate a classifier.  \n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fdfbb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e0617b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv files and convert them into pandas data frames that we can work with\n",
    "# to train a classifier that uses passenger data to make predictions about whether \n",
    "# or not each passenger survived. we will compare the predictions against a source\n",
    "# of truth to determine the accuracy of the model and potentially make some improvements\n",
    "\n",
    "# train.csv contains passenger features and survival outcomes (Survived), used to train\n",
    "# the model. test.csv contains features only, used to predict survival for submission.\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# test_ids is used at the very end of the exercise once we have a prediction\n",
    "# for each row. we'll use the passenger ids to indicate the results of the model\n",
    "test_passenger_ids = test[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af76088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FamilyCat</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>Title</th>\n",
       "      <th>HasCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Middle</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex Embarked  AgeBin FamilyCat FareBin Title  HasCabin\n",
       "0         0       3    male        S   Adult         1       0    Mr         0\n",
       "1         1       1  female        C  Middle         1       3   Mrs         1\n",
       "2         1       3  female        S   Adult         0       1  Miss         0\n",
       "3         1       1  female        S   Adult         1       3   Mrs         1\n",
       "4         0       3    male        S   Adult         0       1    Mr         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the data and limit to the \"features\" (column names) we want to use\n",
    "# in the Logistic Regression classifier below.\n",
    "def clean(data):\n",
    "    \n",
    "    # drop the following columns, as they will not be used in classifying\n",
    "    # whether a passenger lived or died. cabin would actually be a good\n",
    "    # thing to consider, if we could know where the cabin was located on\n",
    "    # the ship. for example, do cabins closer to lifeboats, or further away\n",
    "    # from point of impact (etc) correlate with survival rates?\n",
    "    data = data.drop([\"Ticket\", \"PassengerId\"], axis=1)\n",
    "    \n",
    "    data['AgeBin'] = pd.cut(data['Age'], bins=[0, 12, 18, 35, 60, 120], labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    \n",
    "    # an alternative to filling the age column's empty rows with \n",
    "    # the median is to add a new category and fill na rows with it\n",
    "    data['AgeBin'] = data['AgeBin'].cat.add_categories(['Missing']).fillna('Missing')\n",
    "    data = data.drop(['Age'], axis=1)\n",
    "    \n",
    "    # fill na with S because that is the most commonly embarked location. \n",
    "    # adding an Unknown value here would just increase the number \n",
    "    # of possible categories this is handled  # outside of the for \n",
    "    # loop because Embarked is categorical, unlike the numerical columns above\n",
    "    data['Embarked'] = data[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    # create a new column in the data that accounts for the size of \n",
    "    # the passengers family. add one at the end to include the \n",
    "    # passenger\n",
    "    data[\"FamilyCount\"] = data[\"SibSp\"] + data[\"Parch\"] + 1\n",
    "    data['FamilyCat'] = pd.cut(\n",
    "        data['FamilyCount'], \n",
    "        bins=[0, 1, 4, 11], \n",
    "        # alone, small large. use numbers here instead of words\n",
    "        labels=[0, 1, 2]\n",
    "    )\n",
    "    data = data.drop(['SibSp', 'Parch', 'FamilyCount'], axis=1)\n",
    "    \n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "    # fare has a very wide range of 0-500+, which can skew the \n",
    "    # Logistic Regression model, as it assumes linear relationships.\n",
    "    # binning into equally sized groups reduces sensitivity to outliers\n",
    "    # and captures which fare ranges may correlate with survival\n",
    "    data['FareBin'] = pd.qcut(data['Fare'], 4, labels=[0, 1, 2, 3])\n",
    "    data = data.drop(['Fare'], axis=1)\n",
    "    \n",
    "    # extract any substring of the Name column that ends with `.`\n",
    "    # this is useful because, to an extent, we can infer social \n",
    "    # status and age from the title.\n",
    "    data['Title'] = data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    \n",
    "    # handle some of the edge cases\n",
    "    data['Title'] = data['Title'].replace(\n",
    "        ['Lady', 'Countess', 'Capt', 'Col', 'Don', \n",
    "         'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], \n",
    "        # replace uncommon values with a single value, so \n",
    "        # as to allow the model to focus on more common values\n",
    "        'Rare'\n",
    "    )\n",
    "    data['Title'] = data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    data['HasCabin'] = data['Cabin'].notnull().astype(int)\n",
    "    \n",
    "    data = data.drop(\"Cabin\", axis=1)\n",
    "    data = data.drop('Name', axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# use and reuse the clean function to clean the data for both sets\n",
    "data = clean(data)\n",
    "test = clean(test)\n",
    "\n",
    "# preview the cleaned data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67795613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1 2]\n",
      "[0 1 2 3 4]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# instantiate a LabelEncoder to use on Sex and Embarked.\n",
    "# this will assign 0 to female and a 1 to male. need \n",
    "# to do this  because LogisticRegression requires all \n",
    "# numeric inputs\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "cols = [\"Sex\", \"Embarked\", \"Title\", \"AgeBin\"]\n",
    "\n",
    "# encode Sex => female=0, male=1  \n",
    "# Embarked => C=0, Q=1, S=2, U=3\n",
    "# etc.\n",
    "for col in cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    test[col] = le.fit_transform(test[col])\n",
    "    # le.classes_ shows the unique values that the encoder has \n",
    "    # identified and will transform into more readable values\n",
    "    # that will be used in the modeling\n",
    "    print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2f74f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract Survived as the target (y) and other columns as features (X)\n",
    "\n",
    "# make a copy of the survived column off of the data frame\n",
    "y = data[\"Survived\"]\n",
    "# after making the copy, drop the column before we pass it into the training\n",
    "X = data.drop(\"Survived\", axis=1)\n",
    "\n",
    "# divide the data into two parts: one to train the model (80%) and \n",
    "# another to test its predictions (20%). this split is important to \n",
    "# check how well the model works on new, unseen data, ensuring it \n",
    "# doesn’t just memorize the training data. can't use the complete dataset \n",
    "# for both training and testing would overestimate the model’s \n",
    "# performance, as it would already know the answers. test_size=0.2 \n",
    "# means 20% is used for testing, and random_state=42 keeps the split \n",
    "# consistent each time the code runs.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "393c4a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Coefficients:\n",
      "  Pclass         : -0.535\n",
      "  Sex            : -2.652\n",
      "  Embarked       : -0.343\n",
      "  AgeBin         : -0.184\n",
      "  FamilyCat      : -0.520\n",
      "  FareBin        : 0.220\n",
      "  Title          : -0.231\n",
      "  HasCabin       : 0.618\n",
      "Intercept: 3.365\n"
     ]
    }
   ],
   "source": [
    "# this seems to be the real ML part of the model. LogisticRegression takes in\n",
    "# the training data, which includes the `Survived` column. this is important\n",
    "# because we need to start to draw conclusions from the characteristics of \n",
    "# those who survived and those who did not. the `clf` name is a convention that\n",
    "# is an abbreviation for \"classifier\"\n",
    "\n",
    "# train the model to learn which passenger traits (like sex or class) predict \n",
    "# survival. `.fit` uses the training data to figure out how much each trait\n",
    "# matters for predicting whether someone survived or died, preparing the \n",
    "# model to make predictions later. random_state=0 keeps results consistent, \n",
    "# and max_iter=1000 ensures the model finishes learning.\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "# printing the feature coefficients shows that the strongest indicator of\n",
    "# survival was \"Sex\", which had a coefficient of 2.6. \n",
    "coef_dict = dict(zip(X.columns, clf.coef_[0]))\n",
    "print(\"Feature Coefficients:\")\n",
    "for feature, coef in coef_dict.items():\n",
    "    print(f\"  {feature:<15}: {coef:.3f}\")\n",
    "\n",
    "print(f\"Intercept: {clf.intercept_[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef38830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict survival on the validation set. clf.predict computes probabilities and\n",
    "# outputs 1 (survived) if >= 0.5, or 0 (died)\n",
    "predictions = clf.predict(X_val)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# calculate accuracy by comparing predictions to true labels (y_val). 81% accuracy\n",
    "# means 81% of predictions are correct\n",
    "accuracy_score(y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "744f2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict survival for the test set. clf.predict outputs 1 (survived) if probability\n",
    "# >= 0.5, else 0 (died), for submission\n",
    "submission_preds = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8a7df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame with PassengerId and Survived columns.\n",
    "# test_passenger_ids.values is a list of passenger ids that was\n",
    "# declared in the first codeblock at the top of this notebook.\n",
    "# submission_preds is a list of 0s and 1s indicating the results of\n",
    "# the predictive model. 0 is \"died\" and 1 is \"survived\"\n",
    "df = pd.DataFrame({ \"PassengerId\": test_passenger_ids.values, \"Survived\": submission_preds })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "171929d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data frame into a csv. \n",
    "# index=False excludes index values from being added\n",
    "# to each row\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
